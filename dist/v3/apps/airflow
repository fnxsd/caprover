{"captainVersion":2,"dockerCompose":{"services":{"$$cap_appname-init":{"command":["-c","function ver() {\n  printf \"%04d%04d%04d%04d\" $${1//./ }\n}\nairflow_version=$$(gosu airflow airflow version)\nairflow_version_comparable=$$(ver $${airflow_version})\nmin_airflow_version=2.2.0\nmin_airflow_version_comparable=$$(ver $${min_airflow_version})\nif (( airflow_version_comparable < min_airflow_version_comparable )); then\n  echo\n  echo -e \"\\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\\e[0m\"\n  echo \"The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!\"\n  echo\n  exit 1\nfi\nif [[ -z \"\" ]]; then\n  echo\n  echo -e \"\\033[1;33mWARNING!!!: AIRFLOW_UID not set!\\e[0m\"\n  echo \"If you are on Linux, you SHOULD follow the instructions below to set \"\n  echo \"AIRFLOW_UID environment variable, otherwise files will be owned by root.\"\n  echo \"For other operating systems you can get rid of the warning with manually created .env file:\"\n  echo \"    See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user\"\n  echo\nfi\none_meg=1048576\nmem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))\ncpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)\ndisk_available=$$(df / | tail -1 | awk '{print $$4}')\nwarning_resources=\"false\"\nif (( mem_available < 4000 )) ; then\n  echo\n  echo -e \"\\033[1;33mWARNING!!!: Not enough memory available for Docker.\\e[0m\"\n  echo \"At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))\"\n  echo\n  warning_resources=\"true\"\nfi\nif (( cpus_available < 2 )); then\n  echo\n  echo -e \"\\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\\e[0m\"\n  echo \"At least 2 CPUs recommended. You have $${cpus_available}\"\n  echo\n  warning_resources=\"true\"\nfi\nif (( disk_available < one_meg * 10 )); then\n  echo\n  echo -e \"\\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\\e[0m\"\n  echo \"At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))\"\n  echo\n  warning_resources=\"true\"\nfi\nif [[ $${warning_resources} == \"true\" ]]; then\n  echo\n  echo -e \"\\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\\e[0m\"\n  echo \"Please follow the instructions to increase amount of resources available:\"\n  echo \"   https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin\"\n  echo\nfi\nmkdir -p /sources/logs /sources/dags /sources/plugins\nchown -R \":0\" /sources/{logs,dags,plugins}\nexec /entrypoint airflow version\n"],"depends_on":{"$$cap_appname-postgres":{"condition":"service_healthy"},"$$cap_appname-redis":{"condition":"service_healthy"}},"entrypoint":["/bin/bash"],"environment":{"_AIRFLOW_DB_UPGRADE":"true","_AIRFLOW_WWW_USER_CREATE":"true","_AIRFLOW_WWW_USER_PASSWORD":"$$cap_airflow_www_password","_AIRFLOW_WWW_USER_USERNAME":"$$cap_airflow_www_user","_PIP_ADDITIONAL_REQUIREMENTS":"$$cap_pip_additional_requirements","AIRFLOW__API__AUTH_BACKENDS":"airflow.api.auth.backend.basic_auth","AIRFLOW__CELERY__BROKER_URL":"redis://:@srv-captain--$$cap_appname-redis:6379/0","AIRFLOW__CELERY__RESULT_BACKEND":"db+postgresql://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION":"true","AIRFLOW__CORE__EXECUTOR":"CeleryExecutor","AIRFLOW__CORE__FERNET_KEY":"$$cap_appname_fernet_key","AIRFLOW__CORE__LOAD_EXAMPLES":"true","AIRFLOW__CORE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__DATABASE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow"},"image":"apache/airflow:$$cap_airflow_version","volumes":["$$cap_appname-dags:/opt/airflow/dags","$$cap_appname-logs:/opt/airflow/logs","$$cap_appname-plugins:/opt/airflow/plugins"],"notExposeAsWebApp":"true"},"$$cap_appname-postgres":{"image":"postgres:13","environment":{"POSTGRES_USER":"airflow","POSTGRES_PASSWORD":"airflow","POSTGRES_DB":"airflow"},"volumes":["$$cap_appname-postgres-db-volume:/var/lib/postgresql/data"],"healthcheck":{"test":["CMD","pg_isready","-U","airflow"],"interval":"5s","retries":5},"restart":"always"},"$$cap_appname-redis":{"image":"redis:7","healthcheck":{"test":["CMD","redis-cli","ping"],"interval":"5s","timeout":"30s","retries":50},"restart":"always","notExposeAsWebApp":"true"},"$$cap_appname-webserver":{"environment":{"_PIP_ADDITIONAL_REQUIREMENTS":"$$cap_pip_additional_requirements","AIRFLOW__API__AUTH_BACKENDS":"airflow.api.auth.backend.basic_auth","AIRFLOW__CELERY__BROKER_URL":"redis://:@srv-captain--$$cap_appname-redis:6379/0","AIRFLOW__CELERY__RESULT_BACKEND":"db+postgresql://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION":"true","AIRFLOW__CORE__EXECUTOR":"CeleryExecutor","AIRFLOW__CORE__FERNET_KEY":"$$cap_appname_fernet_key","AIRFLOW__CORE__LOAD_EXAMPLES":"true","AIRFLOW__CORE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__DATABASE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow"},"command":"webserver","healthcheck":{"test":["CMD","curl","--fail","http://localhost:8080/health"],"interval":"10s","timeout":"10s","retries":5},"restart":"always","depends_on":{"$$cap_appname-init":{"condition":"service_completed_successfully"},"$$cap_appname-postgres":{"condition":"service_healthy"},"$$cap_appname-redis":{"condition":"service_healthy"}},"image":"apache/airflow:$$cap_airflow_version","volumes":["$$cap_appname-dags:/opt/airflow/dags","$$cap_appname-logs:/opt/airflow/logs","$$cap_appname-plugins:/opt/airflow/plugins"],"containerHttpPort":"8080"},"$$cap_appname-scheduler":{"environment":{"_PIP_ADDITIONAL_REQUIREMENTS":"$$cap_pip_additional_requirements","AIRFLOW__API__AUTH_BACKENDS":"airflow.api.auth.backend.basic_auth","AIRFLOW__CELERY__BROKER_URL":"redis://:@srv-captain--$$cap_appname-redis:6379/0","AIRFLOW__CELERY__RESULT_BACKEND":"db+postgresql://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION":"true","AIRFLOW__CORE__EXECUTOR":"CeleryExecutor","AIRFLOW__CORE__FERNET_KEY":"$$cap_appname_fernet_key","AIRFLOW__CORE__LOAD_EXAMPLES":"true","AIRFLOW__CORE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__DATABASE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow"},"image":"apache/airflow:$$cap_airflow_version","command":"scheduler","healthcheck":{"test":["CMD-SHELL","airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\""],"interval":"10s","timeout":"10s","retries":5},"restart":"always","depends_on":{"$$cap_appname-init":{"condition":"service_completed_successfully"},"$$cap_appname-postgres":{"condition":"service_healthy"},"$$cap_appname-redis":{"condition":"service_healthy"}},"volumes":["$$cap_appname-dags:/opt/airflow/dags","$$cap_appname-logs:/opt/airflow/logs","$$cap_appname-plugins:/opt/airflow/plugins"],"notExposeAsWebApp":"true"},"$$cap_appname-worker":{"image":"apache/airflow:$$cap_airflow_version","command":"celery worker","healthcheck":{"test":["CMD-SHELL","celery --app airflow.executors.celery_executor.app inspect ping -d \"celery@$${HOSTNAME}\""],"interval":"10s","timeout":"10s","retries":5},"environment":{"_PIP_ADDITIONAL_REQUIREMENTS":"$$cap_pip_additional_requirements","AIRFLOW__API__AUTH_BACKENDS":"airflow.api.auth.backend.basic_auth","AIRFLOW__CELERY__BROKER_URL":"redis://:@srv-captain--$$cap_appname-redis:6379/0","AIRFLOW__CELERY__RESULT_BACKEND":"db+postgresql://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION":"true","AIRFLOW__CORE__EXECUTOR":"CeleryExecutor","AIRFLOW__CORE__FERNET_KEY":"$$cap_appname_fernet_key","AIRFLOW__CORE__LOAD_EXAMPLES":"true","AIRFLOW__CORE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__DATABASE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","DUMB_INIT_SETSID":"0"},"restart":"always","depends_on":{"$$cap_appname-init":{"condition":"service_completed_successfully"},"$$cap_appname-postgres":{"condition":"service_healthy"},"$$cap_appname-redis":{"condition":"service_healthy"}},"volumes":["$$cap_appname-dags:/opt/airflow/dags","$$cap_appname-logs:/opt/airflow/logs","$$cap_appname-plugins:/opt/airflow/plugins"],"notExposeAsWebApp":"true"},"$$cap_appname-triggerer":{"environment":{"_PIP_ADDITIONAL_REQUIREMENTS":"$$cap_pip_additional_requirements","AIRFLOW__API__AUTH_BACKENDS":"airflow.api.auth.backend.basic_auth","AIRFLOW__CELERY__BROKER_URL":"redis://:@srv-captain--$$cap_appname-redis:6379/0","AIRFLOW__CELERY__RESULT_BACKEND":"db+postgresql://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION":"true","AIRFLOW__CORE__EXECUTOR":"CeleryExecutor","AIRFLOW__CORE__FERNET_KEY":"$$cap_appname_fernet_key","AIRFLOW__CORE__LOAD_EXAMPLES":"true","AIRFLOW__CORE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow","AIRFLOW__DATABASE__SQL_ALCHEMY_CONN":"postgresql+psycopg2://airflow:airflow@srv-captain--$$cap_appname-postgres/airflow"},"image":"apache/airflow:$$cap_airflow_version","command":"triggerer","healthcheck":{"test":["CMD-SHELL","airflow jobs check --job-type TriggererJob --hostname \"$${HOSTNAME}\""],"interval":"10s","timeout":"10s","retries":5},"restart":"always","depends_on":{"$$cap_appname-init":{"condition":"service_completed_successfully"},"$$cap_appname-postgres":{"condition":"service_healthy"},"$$cap_appname-redis":{"condition":"service_healthy"}},"volumes":["$$cap_appname-dags:/opt/airflow/dags","$$cap_appname-logs:/opt/airflow/logs","$$cap_appname-plugins:/opt/airflow/plugins"],"notExposeAsWebApp":"true"}}},"variables":[{"id":"$$cap_airflow_version","label":"Airflow Version Tag ","description":"Checkout their docker page for the valid tags https://hub.docker.com/r/apache/airflow/tags","defaultValue":"2.3.1"},{"id":"$$cap_airflow_www_user","label":"Airflow User","defaultValue":"airflow"},{"id":"$$cap_airflow_www_password","label":"Airflow Password","defaultValue":"airflow"},{"id":"$$cap_airflow_fernet_key","label":"Airflow Fernet Key","defaultValue":"$$cap_gen_random_hex(32)"},{"id":"$$cap_pip_additional_requirements","label":"Additional Pip Requirements","defaultValue":""}],"instructions":{"start":"Install Airflow","end":"Have fun"},"displayName":"airflow","isOfficial":false,"description":"Airflow is a platform to create and run DAGs. It is a tool for automation of complex tasks.","documentation":"Install an airflow instance"}
